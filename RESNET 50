import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Add, ReLU, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.utils import to_categorical
from PIL import Image
from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score

# Path to the dataset directory
train_dir = '/Users/anommahartha/DATA/PY/DAGING/V3/DATASET_TRAIN'
test_dir = '/Users/anommahartha/DATA/PY/DAGING/V3/DATASET_TEST'
output_dir = '/Users/anommahartha/DATA/PY/DAGING/V3_RESNET/'


# Function to read the dataset and ignore .DS_Store folders and files
def read_dataset(directory, img_height, img_width, with_filenames=False):
    images = []
    labels = []
    filenames = []  # Add a list to store the file names
    classes = os.listdir(directory)
    for idx, class_name in enumerate(classes):
        if class_name == '.DS_Store':
            continue  # Ignore the .DS_Store folder
        class_dir = os.path.join(directory, class_name)

        # Ignore .DS_Store folders
        if not os.path.isdir(class_dir):
            continue

        for img_name in tqdm(os.listdir(class_dir), desc=f'Reading {class_name}'):
            if img_name == '.DS_Store':
                continue  # Ignore .DS_Store files
            img_path = os.path.join(class_dir, img_name)
            img = Image.open(img_path)  # Read the image using PIL
            img = img.resize((img_width, img_height))  # Resize the image to match the model
            img_array = np.array(img)

            # Check if the label is valid (within the range [0, 2])
            if 0 <= idx < 4:
                images.append(img_array)
                labels.append(idx)
                filenames.append(img_name)  # Save the file name
            else:
                print(f"Skipping image with an invalid label: {img_name}")

    if with_filenames:
        return np.array(images), np.array(labels), filenames
    else:
        return np.array(images), np.array(labels)

#HYPERPARAMETER
imgsize = 50
epoch = 50
batchsize = 64


# Image size expected by the CNN model
img_width, img_height = imgsize, imgsize

# Read training and testing data
train_images, train_labels = read_dataset(train_dir, img_height, img_width)
test_images, test_labels, test_filenames = read_dataset(test_dir, img_height, img_width, with_filenames=True)

# Normalize pixel values to the range [0, 1]
train_images = train_images.astype('float32') / 255.0
test_images = test_images.astype('float32')

# Define the number of classes
num_classes = 3

# Convert labels to one-hot encoded
train_labels = to_categorical(train_labels, num_classes=num_classes)

# Step 1: Define the ResNet architecture
input_tensor = Input(shape=(img_height, img_width, 3))


# Stage 1: 64x64
x = MaxPooling2D((2, 2))(input_tensor)
x = ReLU()(x)
x = BatchNormalization()(x)
x = Conv2D(64, (3, 3), padding='same')(x)

# Stage 2: 32x32
# Define identity block
def identity_block(x, filters, stage, block):
    conv_name_base = f'res{stage}{block}_branch'
    bn_name_base = f'bn{stage}{block}_branch'

    x_shortcut = x

    x = Conv2D(filters, (3, 3), padding='same', name=f'{conv_name_base}2a')(x)
    x = BatchNormalization(name=f'{bn_name_base}2a')(x)
    x = ReLU()(x)

    x = Conv2D(filters, (3, 3), padding='same', name=f'{conv_name_base}2b')(x)
    x = BatchNormalization(name=f'{bn_name_base}2b')(x)

    x = Add()([x, x_shortcut])
    x = ReLU()(x)
    x = BatchNormalization()(x)
    return x

# Define convolutional block
def convolutional_block(x, filters, stage, block, strides=(2, 2)):
    conv_name_base = f'res{stage}{block}_branch'
    bn_name_base = f'bn{stage}{block}_branch'

    x_shortcut = x

    x = Conv2D(filters, (3, 3), padding='same', strides=strides, name=f'{conv_name_base}2a')(x)
    x = BatchNormalization(name=f'{bn_name_base}2a')(x)
    x = ReLU()(x)

    x = Conv2D(filters, (3, 3), padding='same', name=f'{conv_name_base}2b')(x)
    x = BatchNormalization(name=f'{bn_name_base}2b')(x)

    x_shortcut = Conv2D(filters, (1, 1), strides=strides, name=f'{conv_name_base}1')(x_shortcut)
    x_shortcut = BatchNormalization(name=f'{bn_name_base}1')(x_shortcut)

    x = Add()([x, x_shortcut])
    x = ReLU()(x)
    x = BatchNormalization()(x)
    return x

# Implement ResNet stages
# Stage 3: 16x16
x = identity_block(x, 64, stage=2, block='a')
x = identity_block(x, 64, stage=2, block='b')

# Stage 4: 8x8
x = convolutional_block(x, 128, stage=3, block='a')
x = identity_block(x, 128, stage=3, block='b')

# Stage 5: 4x4
x = convolutional_block(x, 256, stage=4, block='a')
x = identity_block(x, 256, stage=4, block='b')

# Stage 6: 1x1
x = AveragePooling2D((4, 4))(x)
x = Flatten()(x)
x = Dense(256, activation='relu')(x)
x = tf.keras.layers.Dropout(0.5)(x)
output = Dense(num_classes, activation='softmax')(x)

# Create the model
model = Model(inputs=input_tensor, outputs=output)

# Step 2: Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Step 3: Train the model using the training data
history = model.fit(train_images, train_labels, epochs=epoch, batch_size=batchsize, validation_split=0.2)

# Get training loss, training accuracy, validation loss, and validation accuracy from history
training_loss = history.history['loss']
print(f'Training loss: {training_loss[-1]:.4f}')

training_accuracy = history.history['accuracy']
print(f'Training accuracy: {training_accuracy[-1] * 100:.2f}%')

# Step 4: Evaluate the model using the testing data
test_labels_one_hot = to_categorical(test_labels, num_classes=num_classes)
test_loss, test_accuracy = model.evaluate(test_images, test_labels_one_hot, verbose=1)
print(f'Test accuracy: {test_accuracy * 100:.2f}%')

# After training, print the validation accuracy
validation_loss = history.history['val_loss']
print(f'Validation loss: {validation_loss[-1]:.4f}')

validation_accuracy = history.history['val_accuracy'][-1]
print(f'Validation accuracy: {validation_accuracy * 100:.2f}%')

# Predict class labels for the testing data
predictions = model.predict(test_images)
predicted_labels = np.argmax(predictions, axis=1)

# Convert class label indices to class names (types of meat)
class_names = os.listdir(train_dir)
predicted_class_names = [class_names[label_idx] for label_idx in predicted_labels]



#EVALUASI 4 KATEGORI
# Hitung confusion matrix
conf_matrix = confusion_matrix(test_labels, predicted_labels)

# Hitung presisi
precision = precision_score(test_labels, predicted_labels, average='macro')

# Hitung recall
recall = recall_score(test_labels, predicted_labels, average='macro')

# Hitung F1 score
f1 = f1_score(test_labels, predicted_labels, average='macro')

# Hitung akurasi
accuracy = accuracy_score(test_labels, predicted_labels)

# Hitung jumlah data yang benar-benar cocok (true predictions)
true_predictions = np.sum(np.diag(conf_matrix))


# Simpan hasil perhitungan metrik evaluasi dalam file teks
output_folder_name = f'{img_width}x{img_height}_{len(history.epoch)}_Epoch'
output_folder_path = os.path.join(output_dir, output_folder_name)

if not os.path.exists(output_folder_path):
    os.makedirs(output_folder_path)

# Simpan hasil perhitungan metrik evaluasi dalam file teks
with open(os.path.join(output_folder_path, f'metrics_{img_width}x{img_height}_{len(history.epoch)}_Epoch.txt'), 'w') as output_file:
    output_file.write(f'Confusion Matrix:\n{conf_matrix}\n')
    output_file.write(f'Akurasi : {accuracy * 100:.2f}%\n')
    output_file.write(f'Presisi : {precision * 100 :.2f}%\n')
    output_file.write(f'Recall: {recall * 100:.2f}%\n')
    output_file.write(f'F1 Score: {f1 * 100:.2f}%\n')
    output_file.write(f'True Predictions: {true_predictions}\n')



# Cetak nama gambar, jenis daging, dan akurasi untuk setiap gambar dalam data pengujian
with open(os.path.join(output_folder_path, f'test_results_{img_width}x{img_height}_{len(history.epoch)}_Epoch.txt'), 'w') as output_file:
    output_file.write("Image Name, True Class, Predicted Class\n")
    for i in range(len(test_images)):
        image_name = test_filenames[i]
        true_class = class_names[test_labels[i]]
        predicted_class = predicted_class_names[i]
        output_file.write(f"{image_name}, {true_class}, {predicted_class}\n")


# Simpan hasil training ke dalam file teks
with open(os.path.join(output_folder_path, f'hasil_training_{img_width}x{img_height}_{len(history.epoch)}_Epoch.txt'), 'w') as output_file:
    output_file.write(f'History: {history.history}\n')
    output_file.write(f'Image Width: {img_width}\n')
    output_file.write(f'Image Height: {img_height}\n')
    output_file.write(f'Number of Epochs: {len(history.epoch)}\n')
    output_file.write(f'Training loss: {training_loss[-1]:.4f}\n')
    output_file.write(f'Training accuracy: {training_accuracy[-1] * 100:.2f}%\n')
    output_file.write(f'Test accuracy: {test_accuracy * 100:.2f}%\n')
    output_file.write(f'Validation loss: {validation_loss[-1]:.4f}\n')
    output_file.write(f'Validation accuracy: {validation_accuracy * 100:.2f}%\n')

# Simpan model ke dalam file .h5
model.save(os.path.join(output_folder_path, f'model_daging{img_width}x{img_height}_{len(history.epoch)}_Epoch.keras'))


# Visualisasi akurasi dan loss selama pelatihan
plt.figure(figsize=(12, 4))

# Akurasi pelatihan dan validasi
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Loss pelatihan dan validasi
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
# Simpan gambar grafik
plt.savefig(os.path.join(output_folder_path, f'grafik_training_{img_width}x{img_height}_{len(history.epoch)}_Epoch.png'))
plt.show()
